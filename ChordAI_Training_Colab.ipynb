{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChordAI - Model Training on Google Colab\n",
    "\n",
    "Bu notebook ChordAI projesinin LSTM modelini Google Colab'da eÄŸitmek iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.\n",
    "\n",
    "## AdÄ±mlar:\n",
    "1. GitHub repo'yu klonla\n",
    "2. Gerekli paketleri yÃ¼kle\n",
    "3. Modeli eÄŸit\n",
    "4. Model dosyasÄ±nÄ± indir\n",
    "5. TensorFlow.js'e dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "\n",
    "**GPU Runtime kullanmayÄ± unutma!**\n",
    "Runtime > Change runtime type > Hardware accelerator: GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup - GitHub Repo Clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone https://github.com/bufyyy/chordai.git\n",
    "%cd chordai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow==2.15.0 numpy pandas matplotlib scikit-learn tensorflowjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Check dataset files\n",
    "dataset_files = [\n",
    "    'dataset/train.json',\n",
    "    'dataset/val.json',\n",
    "    'dataset/test.json',\n",
    "    'dataset/chord_vocab.json',\n",
    "    'dataset/metadata_vocab.json'\n",
    "]\n",
    "\n",
    "for file in dataset_files:\n",
    "    exists = os.path.exists(file)\n",
    "    size = os.path.getsize(file) if exists else 0\n",
    "    print(f\"{'âœ“' if exists else 'âœ—'} {file}: {size:,} bytes\")\n",
    "\n",
    "# Load and check sample data\n",
    "with open('dataset/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "    print(f\"\\nTraining samples: {len(train_data)}\")\n",
    "    print(\"Sample:\", train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model\n",
    "\n",
    "Bu adÄ±m 10-20 dakika sÃ¼recek (GPU ile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd model-training\n",
    "\n",
    "# Train with optimal settings for Colab\n",
    "!python train_model.py --epochs 50 --batch-size 32 --lr 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set and generate samples\n",
    "!python evaluate_model.py --model output/chord_model_final.h5 --evaluate --generate --num-samples 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display training history\n",
    "with open('output/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_title('Model Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['accuracy'], label='Train Accuracy')\n",
    "axes[1].plot(history['val_accuracy'], label='Val Accuracy')\n",
    "axes[1].set_title('Model Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy: {history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Convert to TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to TensorFlow.js format with quantization\n",
    "!python convert_pipeline.py --model output/chord_model_final.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Check Converted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check converted files\n",
    "import os\n",
    "\n",
    "tfjs_path = '../client/public/model'\n",
    "\n",
    "print(\"TensorFlow.js Model Files:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for root, dirs, files in os.walk(tfjs_path):\n",
    "    level = root.replace(tfjs_path, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        size = os.path.getsize(file_path)\n",
    "        size_mb = size / (1024 * 1024)\n",
    "        print(f\"{sub_indent}{file} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Calculate total size\n",
    "total_size = 0\n",
    "for root, dirs, files in os.walk(tfjs_path):\n",
    "    for file in files:\n",
    "        total_size += os.path.getsize(os.path.join(root, file))\n",
    "\n",
    "print(f\"\\nTotal Model Size: {total_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Files\n",
    "\n",
    "Model eÄŸitimi tamamlandÄ±! Åžimdi dosyalarÄ± indir:\n",
    "\n",
    "1. **Keras Model**: `output/chord_model_final.h5`\n",
    "2. **TensorFlow.js Model**: `../client/public/model/` klasÃ¶rÃ¼nÃ¼n tamamÄ±\n",
    "3. **Training History**: `output/training_history.json`\n",
    "4. **Test Results**: `output/test_results.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip model files for easy download\n",
    "!zip -r chordai_trained_model.zip output/ ../client/public/model/\n",
    "\n",
    "print(\"âœ… Model files zipped!\")\n",
    "print(\"Download: chordai_trained_model.zip\")\n",
    "print(\"\\nYou can also download individual files:\")\n",
    "print(\"- output/chord_model_final.h5 (Keras model)\")\n",
    "print(\"- ../client/public/model/ (TensorFlow.js model)\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download('chordai_trained_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "Model baÅŸarÄ±yla eÄŸitildi! Åžimdi:\n",
    "\n",
    "1. `chordai_trained_model.zip` dosyasÄ±nÄ± indir\n",
    "2. Zip'i aÃ§\n",
    "3. `client/public/model/` klasÃ¶rÃ¼nÃ¼ projendeki `client/public/model/` ile deÄŸiÅŸtir\n",
    "4. GitHub'a push et:\n",
    "   ```bash\n",
    "   git add client/public/model/\n",
    "   git commit -m \"Add trained AI model\"\n",
    "   git push\n",
    "   ```\n",
    "5. Vercel otomatik deploy edecek\n",
    "6. Demo mode devre dÄ±ÅŸÄ± kalacak ve gerÃ§ek AI Ã§alÄ±ÅŸacak! ðŸŽ‰\n",
    "\n",
    "---\n",
    "\n",
    "**Not**: Model dosyalarÄ± bÃ¼yÃ¼kse Git LFS kullanman gerekebilir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
